{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e933862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c026b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful spectrogram extractions: 5631\n",
      "Failed spectrogram extractions: 0\n",
      "Snoring samples: 5082\n",
      "Non-snoring samples: 476\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 18s 135ms/step - loss: 0.4199 - accuracy: 0.9167 - val_loss: 0.1914 - val_accuracy: 0.9161\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.1379 - accuracy: 0.9411 - val_loss: 0.1246 - val_accuracy: 0.9460\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 0.0796 - accuracy: 0.9686 - val_loss: 0.0677 - val_accuracy: 0.9748\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 0.0514 - accuracy: 0.9799 - val_loss: 0.0848 - val_accuracy: 0.9664\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 0.0423 - accuracy: 0.9853 - val_loss: 0.0717 - val_accuracy: 0.9670\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 0.0287 - accuracy: 0.9889 - val_loss: 0.0700 - val_accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 0.0645 - val_accuracy: 0.9724\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.0375 - val_accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 17s 138ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0297 - val_accuracy: 0.9898\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 18s 144ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.1135 - val_accuracy: 0.9574\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 0.1135 - accuracy: 0.9574\n",
      "Test loss: 0.11352389305830002\n",
      "Test accuracy: 0.9574340581893921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def snore_detector():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(128, 44, 1)),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocess the audio file into a spectrogram\n",
    "def preprocess_audio(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "         \n",
    "    return spectrogram\n",
    "\n",
    "# Load the data\n",
    "def load_data(data_path):\n",
    "    s = 0\n",
    "    n = 0\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    failed_files = []  # To store the file names that failed spectrogram extraction\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                spectrogram = preprocess_audio(file_path)\n",
    "                x_train.append(spectrogram)\n",
    "                if folder_name == 'snoring_nd':\n",
    "                    y_train.append(1)\n",
    "                    s += 1\n",
    "                elif folder_name == 'non':\n",
    "                    y_train.append(0)\n",
    "                    n += 1\n",
    "            except:\n",
    "                failed_files.append(file_path)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    print(\"Successful spectrogram extractions:\", len(x_train))\n",
    "    print(\"Failed spectrogram extractions:\", len(failed_files))\n",
    "    print(\"Snoring samples:\", s)\n",
    "    print(\"Non-snoring samples:\", n)\n",
    "    return x_train, y_train\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def split_data(x, y, test_size=0.3):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "        \n",
    "\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=10):\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs)\n",
    "    model.save('snoring_local3.h5')\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    return loss, accuracy\n",
    "    \n",
    "# Run the program\n",
    "if __name__ == '__main__':\n",
    "    data_path = \"snoringds\"\n",
    "    x, y = load_data(data_path)\n",
    "    x=x[:5558]\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y)\n",
    "    model = snore_detector()\n",
    "    model = train_model(model, x_train, y_train, x_test, y_test)\n",
    "    loss, accuracy = evaluate_model(model, x_test, y_test)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"snoringds\"\n",
    "x, y = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "63f501fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "The audio file does not contain snoring. [[0.00072291]]\n"
     ]
    }
   ],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                rate=RATE, input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "# Read the wave file\n",
    "sample_rate, data = wav.read('output.wav')\n",
    "\n",
    "# Calculate the current number of frames\n",
    "num_frames = len(data)\n",
    "\n",
    "# Calculate the number of frames to add\n",
    "frames_to_add = 44100 - num_frames\n",
    "\n",
    "# Create a zero-filled array with the same number of channels\n",
    "padding = np.zeros((frames_to_add, 44032))\n",
    "z=np.zeros(padding.shape[0])\n",
    "# Concatenate the padding with the original data\n",
    "padded_data = np.concatenate((data,z), axis=0)\n",
    "\n",
    "# Write the padded data to a new wave file\n",
    "wav.write('my_padded_wave_file.wav', sample_rate, padded_data)\n",
    "model = tf.keras.models.load_model('snoring_local.h5')\n",
    "def preprocess_audio(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "    return spectrogram\n",
    "\n",
    "model = tf.keras.models.load_model('snoring_local.h5')\n",
    "\n",
    "new_audio_file_path = 'my_padded_wave_file.wav'\n",
    "new_spectrogram = preprocess_audio(new_audio_file_path)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(np.array([new_spectrogram]))\n",
    "if prediction[0][0] > 0.01:\n",
    "    print('The audio file contains snoring.',prediction)\n",
    "else:\n",
    "    print('The audio file does not contain snoring.',prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4455a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "The audio file does not contain snoring. [[0.00185027]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('snoring_local.h5')\n",
    "def preprocess_audio(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "    return spectrogram\n",
    "\n",
    "model = tf.keras.models.load_model('snoring_local.h5')\n",
    "\n",
    "new_audio_file_path = 'my_padded_wave_file.wav'\n",
    "new_spectrogram = preprocess_audio(new_audio_file_path)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(np.array([new_spectrogram]))\n",
    "if prediction[0][0] > 0.01:\n",
    "    print('The audio file contains snoring.',prediction)\n",
    "else:\n",
    "    print('The audio file does not contain snoring.',prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ffac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.round(y_pred).flatten()\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    return confusion\n",
    "\n",
    "# Run the program\n",
    "if __name__ == '__main__':\n",
    "    data_path = \"snoringds\"\n",
    "    x, y = load_data(data_path)\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y)\n",
    "    model = snore_detector()\n",
    "    model = train_model(model, x_train, y_train, x_test, y_test)\n",
    "    confusion = evaluate_model(model, x_test, y_test)\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion)\n",
    "    \n",
    "    # Plotting the confusion matrix\n",
    "    labels = ['Non-snoring', 'Snoring']\n",
    "    sns.heatmap(confusion, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d54e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement PyQt5.QtWebEngineWidgets (from versions: none)\n",
      "ERROR: No matching distribution found for PyQt5.QtWebEngineWidgets\n"
     ]
    }
   ],
   "source": [
    "!pip install PyQt5.QtWebEngineWidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fc11e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement ui_main (from versions: none)\n",
      "ERROR: No matching distribution found for ui_main\n"
     ]
    }
   ],
   "source": [
    "!pip install ui_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adithya\\anaconda3\\envs\\snorring\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Adithya\\anaconda3\\envs\\snorring\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\Adithya\\anaconda3\\envs\\snorring\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def snore_detector():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(128, 44, 1)),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocess the audio file into a spectrogram\n",
    "def preprocess_audio(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "         \n",
    "    return spectrogram\n",
    "\n",
    "# Load the data\n",
    "def load_data(data_path):\n",
    "    s = 0\n",
    "    n = 0\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    failed_files = []  # To store the file names that failed spectrogram extraction\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                spectrogram = preprocess_audio(file_path)\n",
    "                x_train.append(spectrogram)\n",
    "                if folder_name == 'snoring_nd':\n",
    "                    y_train.append(1)\n",
    "                    s += 1\n",
    "                elif folder_name == 'non':\n",
    "                    y_train.append(0)\n",
    "                    n += 1\n",
    "            except:\n",
    "                failed_files.append(file_path)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    print(\"Successful spectrogram extractions:\", len(x_train))\n",
    "    print(\"Failed spectrogram extractions:\", len(failed_files))\n",
    "    print(\"Snoring samples:\", s)\n",
    "    print(\"Non-snoring samples:\", n)\n",
    "    return x_train, y_train\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def split_data(x, y, test_size=0.3):\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y, test_size=0.25)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=10):\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs)\n",
    "    model.save('snoring_local3.h5')\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    return loss, accuracy\n",
    "\n",
    "# Run the program\n",
    "if __name__ == '__main__':\n",
    "    data_path = \"snoringds\"\n",
    "    x, y = load_data(data_path)\n",
    "    x = x[:5743]\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y)\n",
    "    model = snore_detector()\n",
    "    model = train_model(model, x_train, y_train, x_test, y_test)\n",
    "    loss, accuracy = evaluate_model(model, x_test, y_test)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)\n",
    "\n",
    "    # Calculate predictions for the test data\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05459176",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "n=0\n",
    "failed_files = []  # To store the file names that failed spectrogram extraction\n",
    "for folder_name in os.listdir(\"snoringds\"):\n",
    "    folder_path = os.path.join(\"snoringds\", folder_name)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if folder_name == 'non':\n",
    "            y_train.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5dd92ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2a90cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful spectrogram extractions: 5743\n",
      "Failed spectrogram extractions: 0\n",
      "Snoring samples: 5082\n",
      "Non-snoring samples: 588\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5550, 5670]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m x, y \u001b[38;5;241m=\u001b[39m load_data(data_path)\n\u001b[0;32m     87\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:\u001b[38;5;241m5550\u001b[39m]\n\u001b[1;32m---> 88\u001b[0m x_train, y_train, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m model \u001b[38;5;241m=\u001b[39m snore_detector()\n\u001b[0;32m     90\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(model, x_train, y_train, x_test, y_test)\n",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m, in \u001b[0;36msplit_data\u001b[1;34m(x, y, test_size)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_data\u001b[39m(x, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m):\n\u001b[1;32m---> 69\u001b[0m     x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_train, y_train, x_test, y_test\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snorring\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snorring\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\snorring\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5550, 5670]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def snore_detector():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(128, 44, 1)),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocess the audio file into a spectrogram\n",
    "def preprocess_audio(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "         \n",
    "    return spectrogram\n",
    "\n",
    "# Load the data\n",
    "def load_data(data_path):\n",
    "    s = 0\n",
    "    n = 0\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    failed_files = []  # To store the file names that failed spectrogram extraction\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                spectrogram = preprocess_audio(file_path)\n",
    "                x_train.append(spectrogram)\n",
    "                if folder_name == 'snoring_nd':\n",
    "                    y_train.append(1)\n",
    "                    s += 1\n",
    "                elif folder_name == 'non':\n",
    "                    y_train.append(0)\n",
    "                    n += 1\n",
    "            except:\n",
    "                failed_files.append(file_path)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    print(\"Successful spectrogram extractions:\", len(x_train))\n",
    "    print(\"Failed spectrogram extractions:\", len(failed_files))\n",
    "    print(\"Snoring samples:\", s)\n",
    "    print(\"Non-snoring samples:\", n)\n",
    "    return x_train, y_train\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def split_data(x, y, test_size=0.3):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=10):\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs)\n",
    "    model.save('snoring_local3.h5')\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    return loss, accuracy\n",
    "\n",
    "# Run the program\n",
    "if __name__ == '__main__':\n",
    "    data_path = \"snoringds\"\n",
    "    x, y = load_data(data_path)\n",
    "    x = x[:5550]\n",
    "    x_train, y_train, x_test, y_test = split_data(x, y)\n",
    "    model = snore_detector()\n",
    "    model = train_model(model, x_train, y_train, x_test, y_test)\n",
    "    loss, accuracy = evaluate_model(model, x_test, y_test)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy)\n",
    "\n",
    "    # Calculate predictions for the test data\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50513c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from seaborn) (1.24.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from seaborn) (2.0.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from seaborn) (3.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adithya\\anaconda3\\envs\\snorring\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42c781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
